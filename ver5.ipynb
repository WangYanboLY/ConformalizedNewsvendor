{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection and Feature Importance\n",
    "$$\n",
    "{\\text\\ Importance\\ for\\ feature_i} = {\\text\\ best\\ cost\\ using\\ features_{-i}} / {\\text\\ best\\ cost\\ using\\ all\\ features}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear loss unadjusted 6972.893055621992 loss_adjusted 125.59176725989416\n",
      "quantile loss unadjusted 6883.976768322941 loss_adjusted 126.35026095161547\n",
      "lasso loss unadjusted 6972.873227794408 loss_adjusted 125.58936046320991\n",
      "ridge loss unadjusted 6972.8803913867605 loss_adjusted 125.59206856755274\n",
      "random_forest loss unadjusted 6125.013594244923 loss_adjusted 1645.7233999817074\n",
      "glm loss unadjusted 6972.893055621939 loss_adjusted 125.59176725989492\n",
      "neural_network loss unadjusted 47644.04603620853 loss_adjusted 3552.023744321883\n"
     ]
    }
   ],
   "source": [
    "# feature importance\n",
    "import numpy as np\n",
    "import ConformaQuantile as CQ\n",
    "\n",
    "quantile = 0.8\n",
    "n_samples = 10000\n",
    "n_X1 = 20\n",
    "n_X2 = 2\n",
    "n_X3 = 2\n",
    "interval_length = 100\n",
    "np.random.seed(0)\n",
    "\n",
    "X1 = abs(np.random.normal(6.4, 10, (n_samples, n_X1)))\n",
    "X2 = abs(np.random.normal(0.4, 1, (n_samples, n_X2)))\n",
    "X3 = abs(np.random.normal(0.9, 1, (n_samples, n_X3)))\n",
    "\n",
    "coefficients = abs(np.random.normal(10, 400, n_X1 + n_X2))\n",
    "X = np.hstack((X1, X2, X3))\n",
    "noise = np.random.normal(0, 1, n_samples)\n",
    "\n",
    "X_true = X[:, :(n_X1 + n_X2)]\n",
    "X_observed = np.hstack((X1, X3))\n",
    "Y = np.dot(X_true, coefficients)\n",
    "\n",
    "\n",
    "train_ratio = 0.6\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "models = ['linear', 'quantile', 'lasso', 'ridge', 'random_forest', 'glm', 'neural_network']\n",
    "Y0 = Y + noise\n",
    "loss = {}\n",
    "for model in models:\n",
    "    loss_unadjusted, loss_adjusted = CQ.perform_regression_analysis(X_observed, Y0, train_ratio, test_ratio, validation_ratio, quantile, model_type=model)\n",
    "    # 将结果存储在字典中\n",
    "    loss[model] = {'loss_unadjusted': loss_unadjusted, 'loss_adjusted': loss_adjusted}\n",
    "min_loss_model = min(loss, key=lambda x: loss[x]['loss_adjusted'])\n",
    "min_loss = loss[min_loss_model]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear loss unadjusted 6887.182953043456 loss_adjusted 673.0959679762929\n",
      "quantile loss unadjusted 6389.962687579106 loss_adjusted 674.1611963174726\n",
      "lasso loss unadjusted 6887.167592837898 loss_adjusted 673.0977768786927\n",
      "ridge loss unadjusted 6887.170790270856 loss_adjusted 673.0957768228136\n",
      "random_forest loss unadjusted 6125.010578275807 loss_adjusted 1677.0601830002163\n",
      "glm loss unadjusted 6887.182953043476 loss_adjusted 673.0959679762938\n",
      "neural_network loss unadjusted 48160.63727621098 loss_adjusted 3574.3315251766903\n",
      "\n",
      "linear loss unadjusted 6782.764707821611 loss_adjusted 959.8351474112939\n",
      "quantile loss unadjusted 6102.304501866081 loss_adjusted 959.1899743736889\n",
      "lasso loss unadjusted 6782.753228477607 loss_adjusted 959.8350105276054\n",
      "ridge loss unadjusted 6782.752917936259 loss_adjusted 959.8344331607536\n",
      "random_forest loss unadjusted 6095.493266928759 loss_adjusted 1730.3239174747243\n",
      "glm loss unadjusted 6782.764707821617 loss_adjusted 959.8351474112864\n",
      "neural_network loss unadjusted 47689.501379372596 loss_adjusted 3552.6978256338693\n",
      "\n",
      "linear loss unadjusted 6976.866669888772 loss_adjusted 439.3853319151835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyanbo/miniforge3/envs/ML/lib/python3.11/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile loss unadjusted 6649.608706267647 loss_adjusted 441.50475284070416\n",
      "lasso loss unadjusted 6976.851453641525 loss_adjusted 439.3863652868455\n",
      "ridge loss unadjusted 6976.853800257321 loss_adjusted 439.3845988341793\n",
      "random_forest loss unadjusted 6139.00779476659 loss_adjusted 1640.659081152404\n",
      "glm loss unadjusted 6976.866669888767 loss_adjusted 439.38533191518405\n",
      "neural_network loss unadjusted 47857.68954079838 loss_adjusted 3560.2947624475514\n",
      "\n",
      "linear loss unadjusted 6931.030609637786 loss_adjusted 522.403983103342\n",
      "quantile loss unadjusted 6553.955256936324 loss_adjusted 523.6083561301587\n",
      "lasso loss unadjusted 6931.011671564154 loss_adjusted 522.4049009570582\n",
      "ridge loss unadjusted 6931.018038264665 loss_adjusted 522.4039051116872\n",
      "random_forest loss unadjusted 6133.588562952742 loss_adjusted 1640.1473647853593\n",
      "glm loss unadjusted 6931.030609637756 loss_adjusted 522.4039831033422\n",
      "neural_network loss unadjusted 47961.209657460975 loss_adjusted 3564.4383936975514\n",
      "\n",
      "linear loss unadjusted 6973.661265453268 loss_adjusted 126.02978355565945\n",
      "quantile loss unadjusted 6882.654767819306 loss_adjusted 126.51472314041851\n",
      "lasso loss unadjusted 6973.64121918804 loss_adjusted 126.02207327922059\n",
      "ridge loss unadjusted 6973.648575915882 loss_adjusted 126.02710913296927\n",
      "random_forest loss unadjusted 6135.059619034209 loss_adjusted 1631.8402082324985\n",
      "glm loss unadjusted 6973.661265453269 loss_adjusted 126.0297835556567\n",
      "neural_network loss unadjusted 48151.85062054691 loss_adjusted 3572.987521822551\n",
      "\n",
      "linear loss unadjusted 6889.456034157976 loss_adjusted 871.023186362502\n",
      "quantile loss unadjusted 6285.219240938608 loss_adjusted 875.52985051099\n",
      "lasso loss unadjusted 6889.437762640744 loss_adjusted 871.0211394551692\n",
      "ridge loss unadjusted 6889.443731706552 loss_adjusted 871.0237221734598\n",
      "random_forest loss unadjusted 6129.960080708779 loss_adjusted 1699.3194403582559\n",
      "glm loss unadjusted 6889.456034157955 loss_adjusted 871.0231863625014\n",
      "neural_network loss unadjusted 47966.9269653223 loss_adjusted 3565.968915020441\n",
      "\n",
      "linear loss unadjusted 6971.864359351846 loss_adjusted 128.90691002987398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyanbo/miniforge3/envs/ML/lib/python3.11/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile loss unadjusted 6877.503674931597 loss_adjusted 129.1197915865584\n",
      "lasso loss unadjusted 6971.845694806625 loss_adjusted 128.9102508295954\n",
      "ridge loss unadjusted 6971.8516090636895 loss_adjusted 128.90748940475297\n",
      "random_forest loss unadjusted 6132.194805347104 loss_adjusted 1631.7091278516361\n",
      "glm loss unadjusted 6971.864359351846 loss_adjusted 128.90691002987464\n",
      "neural_network loss unadjusted 48036.63898745365 loss_adjusted 3567.622076739191\n",
      "\n",
      "linear loss unadjusted 6977.895358485986 loss_adjusted 455.41075781980066\n",
      "quantile loss unadjusted 6640.673200576966 loss_adjusted 456.70205903107706\n",
      "lasso loss unadjusted 6977.881739032168 loss_adjusted 455.40751514132603\n",
      "ridge loss unadjusted 6977.882665108964 loss_adjusted 455.4098645488537\n",
      "random_forest loss unadjusted 6129.500525148082 loss_adjusted 1634.475624090607\n",
      "glm loss unadjusted 6977.895358485989 loss_adjusted 455.4107578198008\n",
      "neural_network loss unadjusted 48255.04570052738 loss_adjusted 3577.5861954891907\n",
      "\n",
      "linear loss unadjusted 6974.529406983304 loss_adjusted 192.00139249139656\n",
      "quantile loss unadjusted 6818.969258956914 loss_adjusted 193.11034728879193\n",
      "lasso loss unadjusted 6974.512742578866 loss_adjusted 191.999287044877\n",
      "ridge loss unadjusted 6974.516729829035 loss_adjusted 192.00092344933287\n",
      "random_forest loss unadjusted 6131.399834875176 loss_adjusted 1636.2352409738337\n",
      "glm loss unadjusted 6974.529406983303 loss_adjusted 192.00139249139605\n",
      "neural_network loss unadjusted 48053.84753143558 loss_adjusted 3568.8814358850514\n",
      "\n",
      "linear loss unadjusted 6747.883601722491 loss_adjusted 1283.6129143009373\n",
      "quantile loss unadjusted 5844.8809641909165 loss_adjusted 1283.8542854948926\n",
      "lasso loss unadjusted 6747.8696818499175 loss_adjusted 1283.611435947251\n",
      "ridge loss unadjusted 6747.8718957462115 loss_adjusted 1283.61288494213\n",
      "random_forest loss unadjusted 6073.225504478508 loss_adjusted 1907.5895593719654\n",
      "glm loss unadjusted 6747.883601722475 loss_adjusted 1283.6129143009373\n",
      "neural_network loss unadjusted 48054.72552057133 loss_adjusted 3570.7968171350512\n",
      "\n",
      "linear loss unadjusted 6758.8053040979985 loss_adjusted 1428.5638882318349\n",
      "quantile loss unadjusted 5820.262020053983 loss_adjusted 1441.1659617442472\n",
      "lasso loss unadjusted 6758.794863251609 loss_adjusted 1428.5630892404615\n",
      "ridge loss unadjusted 6758.794862500547 loss_adjusted 1428.5636475033891\n",
      "random_forest loss unadjusted 6094.990438879623 loss_adjusted 1957.36984112632\n",
      "glm loss unadjusted 6758.805304097975 loss_adjusted 1428.563888231838\n",
      "neural_network loss unadjusted 48067.67339417972 loss_adjusted 3571.629220260051\n",
      "\n",
      "linear loss unadjusted 6849.741602285756 loss_adjusted 841.9054303628143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangyanbo/miniforge3/envs/ML/lib/python3.11/site-packages/statsmodels/regression/quantile_regression.py:191: IterationLimitWarning: Maximum number of iterations (1000) reached.\n",
      "  warnings.warn(\"Maximum number of iterations (\" + str(max_iter) +\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quantile loss unadjusted 6245.475665845618 loss_adjusted 841.2854956344378\n",
      "lasso loss unadjusted 6849.726191846395 loss_adjusted 841.9073502861532\n",
      "ridge loss unadjusted 6849.729342135334 loss_adjusted 841.9055412627931\n",
      "random_forest loss unadjusted 6131.356014334839 loss_adjusted 1724.420755720687\n",
      "glm loss unadjusted 6849.741602285741 loss_adjusted 841.905430362815\n",
      "neural_network loss unadjusted 47946.37875953618 loss_adjusted 3564.5710126766908\n",
      "\n",
      "linear loss unadjusted 6960.379814493178 loss_adjusted 230.85776845063933\n",
      "quantile loss unadjusted 6782.754908519702 loss_adjusted 230.74817714359145\n",
      "lasso loss unadjusted 6960.370288018952 loss_adjusted 230.8571400919007\n",
      "ridge loss unadjusted 6960.367208906233 loss_adjusted 230.8580705259122\n",
      "random_forest loss unadjusted 6124.196682978555 loss_adjusted 1635.6662748410097\n",
      "glm loss unadjusted 6960.37981449315 loss_adjusted 230.85776845063998\n",
      "neural_network loss unadjusted 48154.99173630619 loss_adjusted 3572.9275126766906\n",
      "\n",
      "linear loss unadjusted 6730.713983147915 loss_adjusted 1372.5558208268067\n",
      "quantile loss unadjusted 5790.877005573237 loss_adjusted 1374.4066356955648\n",
      "lasso loss unadjusted 6730.701235604416 loss_adjusted 1372.5568368225447\n",
      "ridge loss unadjusted 6730.702718563334 loss_adjusted 1372.5556748771835\n",
      "random_forest loss unadjusted 6053.8919378438795 loss_adjusted 1928.6007247930002\n",
      "glm loss unadjusted 6730.713983147893 loss_adjusted 1372.5558208268062\n",
      "neural_network loss unadjusted 48185.632171041296 loss_adjusted 3575.7695108850517\n",
      "\n",
      "linear loss unadjusted 6973.276954108105 loss_adjusted 138.30528595159666\n",
      "quantile loss unadjusted 6866.369518301844 loss_adjusted 138.7928236997283\n",
      "lasso loss unadjusted 6973.261479641825 loss_adjusted 138.30291863587166\n",
      "ridge loss unadjusted 6973.264180391099 loss_adjusted 138.30435095354443\n",
      "random_forest loss unadjusted 6131.149532023186 loss_adjusted 1640.2909481764689\n",
      "glm loss unadjusted 6973.276954108083 loss_adjusted 138.30528595159856\n",
      "neural_network loss unadjusted 47963.64107561283 loss_adjusted 3564.3542686975516\n",
      "\n",
      "linear loss unadjusted 6428.341356793925 loss_adjusted 2038.133992545626\n",
      "quantile loss unadjusted 5208.673187732799 loss_adjusted 2043.2796632927539\n",
      "lasso loss unadjusted 6428.326514172229 loss_adjusted 2038.1308924981192\n",
      "ridge loss unadjusted 6428.331870347956 loss_adjusted 2038.1326228876603\n",
      "random_forest loss unadjusted 5784.5161903495955 loss_adjusted 2394.516234639169\n",
      "glm loss unadjusted 6428.341356793915 loss_adjusted 2038.1339925456225\n",
      "neural_network loss unadjusted 47762.027178689 loss_adjusted 3560.0812806454405\n",
      "\n",
      "linear loss unadjusted 6898.767776106324 loss_adjusted 1127.67954564692\n",
      "quantile loss unadjusted 6130.727933585697 loss_adjusted 1128.2649627385686\n",
      "lasso loss unadjusted 6898.753404139945 loss_adjusted 1127.676548552489\n",
      "ridge loss unadjusted 6898.755194552261 loss_adjusted 1127.6788541936717\n",
      "random_forest loss unadjusted 6124.781276899475 loss_adjusted 1788.6377698975452\n",
      "glm loss unadjusted 6898.7677761063205 loss_adjusted 1127.67954564692\n",
      "neural_network loss unadjusted 48075.24949212894 loss_adjusted 3570.6591087704405\n",
      "\n",
      "linear loss unadjusted 6991.525642603899 loss_adjusted 374.0912617280247\n",
      "quantile loss unadjusted 6693.30746997304 loss_adjusted 375.1110525354784\n",
      "lasso loss unadjusted 6991.5062747106795 loss_adjusted 374.0915420466731\n",
      "ridge loss unadjusted 6991.51281997728 loss_adjusted 374.0923624311163\n",
      "random_forest loss unadjusted 6140.66480521195 loss_adjusted 1649.9750512467344\n",
      "glm loss unadjusted 6991.5256426038795 loss_adjusted 374.0912617280276\n",
      "neural_network loss unadjusted 48152.69329599857 loss_adjusted 3573.3757267391907\n",
      "\n",
      "linear loss unadjusted 6958.42146388691 loss_adjusted 318.4378542191457\n",
      "quantile loss unadjusted 6715.642972441852 loss_adjusted 317.62580334411916\n",
      "lasso loss unadjusted 6958.406013323029 loss_adjusted 318.4375720742222\n",
      "ridge loss unadjusted 6958.408788915428 loss_adjusted 318.43821295163804\n",
      "random_forest loss unadjusted 6127.808639408188 loss_adjusted 1645.10133274897\n",
      "glm loss unadjusted 6958.421463886914 loss_adjusted 318.4378542191436\n",
      "neural_network loss unadjusted 48063.88197162113 loss_adjusted 3568.81831502044\n",
      "\n",
      "linear loss unadjusted 6900.716802197421 loss_adjusted 829.9000279673398\n",
      "quantile loss unadjusted 6286.328430555474 loss_adjusted 832.6333411012655\n",
      "lasso loss unadjusted 6900.702263086592 loss_adjusted 829.9002012335011\n",
      "ridge loss unadjusted 6900.704247635057 loss_adjusted 829.9007509721303\n",
      "random_forest loss unadjusted 6139.629894580042 loss_adjusted 1712.4112045762263\n",
      "glm loss unadjusted 6900.716802197409 loss_adjusted 829.90002796734\n",
      "neural_network loss unadjusted 47981.846029616725 loss_adjusted 3566.3553485004313\n",
      "\n",
      "linear loss unadjusted 6972.834580398461 loss_adjusted 125.5761605438409\n",
      "quantile loss unadjusted 6883.713893243471 loss_adjusted 126.3899406917857\n",
      "lasso loss unadjusted 6972.816648152428 loss_adjusted 125.57399120430657\n",
      "ridge loss unadjusted 6972.8219433286995 loss_adjusted 125.57410986337896\n",
      "random_forest loss unadjusted 6134.204125590198 loss_adjusted 1641.0427188585397\n",
      "glm loss unadjusted 6972.834580398444 loss_adjusted 125.57616054384032\n",
      "neural_network loss unadjusted 47939.09143540287 loss_adjusted 3564.268889010051\n",
      "\n",
      "linear loss unadjusted 6972.889901789102 loss_adjusted 125.58950751225763\n",
      "quantile loss unadjusted 6883.932599883714 loss_adjusted 126.32211016324408\n",
      "lasso loss unadjusted 6972.872510084014 loss_adjusted 125.58883536720975\n",
      "ridge loss unadjusted 6972.877240221389 loss_adjusted 125.58982718491364\n",
      "random_forest loss unadjusted 6132.315758859152 loss_adjusted 1641.6316252121749\n",
      "glm loss unadjusted 6972.889901789081 loss_adjusted 125.58950751225782\n",
      "neural_network loss unadjusted 48178.446520528596 loss_adjusted 3574.9566579891903\n"
     ]
    }
   ],
   "source": [
    "# feature importance\n",
    "\n",
    "n_features_observed = X_observed.shape[1]\n",
    "loss_modified = {}\n",
    "ratios = []\n",
    "for i in range(n_features_observed):\n",
    "    X_observed_deleted_i = np.delete(X_observed, i, axis=1)\n",
    "    print(X_observed_deleted_i.shape[1])\n",
    "    for model in models:\n",
    "        loss_unadjusted, loss_adjusted = CQ.perform_regression_analysis(X_observed_deleted_i,\n",
    "                                                                         Y0, train_ratio, test_ratio, \n",
    "                                                                         validation_ratio, quantile, \n",
    "                                                                         model_type=model)\n",
    "    # 将结果存储在字典中\n",
    "        loss_modified[model] = {'loss_unadjusted': loss_unadjusted, 'loss_adjusted': loss_adjusted}\n",
    "    min_loss_model = min(loss_modified, key=lambda x: loss[x]['loss_adjusted'])\n",
    "    min_loss_deleted = loss_modified[min_loss_model]\n",
    "    ratio =  min_loss_deleted['loss_adjusted']/ min_loss['loss_adjusted']\n",
    "    ratios.append(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.35951273576132, 7.642645897609925, 3.4985954516072173, 4.15962704985739, 1.0034454575962064, 6.935469184989804, 1.026442449855124, 3.6261631834229533, 1.5287862469935993, 10.220702065946673, 11.374873508165878, 6.70365186335017, 1.8381902673955242, 10.928926079089486, 1.1012311721770893, 16.228531501242642, 8.979077084183656, 2.978688168065473, 2.5355457731429816, 6.60804544407734, 0.9998776229224621, 0.999995818945186]\n"
     ]
    }
   ],
   "source": [
    "print(ratios)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
