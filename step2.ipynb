{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear Demand with misspecification\n",
    "\n",
    "$$\n",
    "D = f(X) + \\epsilon\n",
    "$$\n",
    "其中$f$为一个非线性函数$X = (X_1, X_2)$. 可以观测到的变量为$X_{\\text observed} = (X_1, X_3)$. 基于手中的数据希望得到一个$D|X_{\\text observed}$的条件分位数模型$g(X_{\\text observed})$. \n",
    "\n",
    "## 生成数据的方式f\n",
    "1. 考虑使用一个浅层神经网络构造非线性关系, 网络的参数随机生成或是先给定\n",
    "2. 考虑使用GLM来构造非线性关系，包括Poisson式，指数式等\n",
    "\n",
    "## 模型的选择g\n",
    "1. 线性模型 lasso, ridge and elastic net\n",
    "2. random\n",
    "3. Kernal-based regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV, RidgeCV\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the data\n",
    "# basic settings\n",
    "quantile = 0.4\n",
    "n_samples = 10000\n",
    "n_X1 = 10\n",
    "n_X2 = 2\n",
    "n_X3 = 2\n",
    "interval_length = 100\n",
    "np.random.seed(0)\n",
    "\n",
    "# generate data by GLM with misspecification\n",
    "X1 = abs(np.random.normal(6.4, 10, (n_samples, n_X1)))\n",
    "X2 = abs(np.random.normal(0.4, 1, (n_samples, n_X2)))\n",
    "X3 = abs(np.random.normal(0.9, 1, (n_samples, n_X3)))\n",
    "\n",
    "coefficients = abs(np.random.normal(10, 400, n_X1 + n_X2))\n",
    "X = np.hstack((X1, X2, X3))\n",
    "noise = np.random.normal(0, 16, n_samples)\n",
    "\n",
    "X_true = X[:, :(n_X1 + n_X2)]\n",
    "X_observed = np.hstack((X1, X3))\n",
    "Y = np.dot(X_true, coefficients)\n",
    "Y = Y**(-1/2) + noise\n",
    "\n",
    "train_ratio = 0.6\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.2\n",
    "\n",
    "\n",
    "X_train, X_temp, Y_train, Y_temp = train_test_split(X_observed, Y, test_size=1 - train_ratio, random_state=0)\n",
    "X_test, X_validation, Y_test, Y_validation = train_test_split(X_temp, Y_temp, test_size=validation_ratio/(test_ratio + validation_ratio), random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_const = sm.add_constant(X_train)\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "\n",
    "quantile_reg_model = sm.QuantReg(Y_train, X_train_const).fit(q=quantile)\n",
    "linear_model = sm.OLS(Y_train, X_train_const).fit()\n",
    "lasso = LassoCV(cv=5, random_state=0).fit(X_train_const, Y_train)\n",
    "\n",
    "\n",
    "Y_pred_test = quantile_reg_model.predict(X_test_const)\n",
    "Y_linear_pred_test = linear_model.predict(X_test_const)\n",
    "Y_pred_validation_lasso = lasso.predict(X_test_const)\n",
    "\n",
    "E_i = Y_test - Y_pred_test\n",
    "E_i_linear = Y_test - Y_linear_pred_test\n",
    "E_lasso = Y_test - Y_pred_validation_lasso\n",
    "\n",
    "adjusted_quantile = quantile * (1 + 1 / len(E_i))\n",
    "adjusted_quantile_linear = quantile*(1 + 1 / len(E_i_linear))\n",
    "adjusted_quantile_lasso = quantile * (1 + 1 / len(E_lasso))\n",
    "\n",
    "Q_alpha_E = np.quantile(E_i, adjusted_quantile)\n",
    "Q_alpha_E_linear = np.quantile(E_i_linear, adjusted_quantile_linear)\n",
    "Q_lasso = np.quantile(E_lasso, adjusted_quantile_lasso)\n",
    "\n",
    "X_validation_const = sm.add_constant(X_validation)\n",
    "\n",
    "Y_pred_validation = quantile_reg_model.predict(X_validation_const)\n",
    "Y_pred_validation_adjusted = Y_pred_validation + Q_alpha_E\n",
    "Y_pred_validation_linear = linear_model.predict(X_validation_const)\n",
    "Y_pred_validation_linear_adjusted = Y_pred_validation_linear + Q_alpha_E_linear\n",
    "Y_pred_validation_lasso = lasso.predict(X_validation_const)\n",
    "Y_pred_validation_lasso_adjusted = Y_pred_validation_lasso + Q_lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile Loss Unadjusted: 6.177996898726444 \n",
      " Quantile Loss Adjusted: 6.180261646999584 \n",
      " Linear loss:  6.406016815315599 \n",
      " Linear adjusted loss: 6.172311214996229 \n",
      " Lasso loss:  6.412759295014676 \n",
      " Lasso adjusted loss: 6.183095590049424\n"
     ]
    }
   ],
   "source": [
    "def quantile_loss(y_true, y_pred, quantile):\n",
    "    error = y_true - y_pred\n",
    "    return np.maximum(quantile * error, (quantile - 1) * error).mean()\n",
    "\n",
    "quantile_loss_unadjusted = quantile_loss(Y_validation, Y_pred_validation, quantile)\n",
    "quantile_loss_adjusted = quantile_loss(Y_validation, Y_pred_validation_adjusted, quantile)\n",
    "quantile_loss_linear = quantile_loss(Y_validation, Y_pred_validation_linear, quantile)\n",
    "quantile_loss_linear_adjusted = quantile_loss(Y_validation, Y_pred_validation_linear_adjusted, quantile)\n",
    "quantile_loss_lasso = quantile_loss(Y_validation, Y_pred_validation_lasso, quantile)\n",
    "quantile_loss_lasso_adjusted = quantile_loss(Y_validation, Y_pred_validation_lasso_adjusted, quantile)\n",
    "\n",
    "print(\"Quantile Loss Unadjusted:\", quantile_loss_unadjusted, \"\\n\",  \"Quantile Loss Adjusted:\", quantile_loss_adjusted, \"\\n\", \n",
    "      \"Linear loss: \", quantile_loss_linear,  \"\\n\",\"Linear adjusted loss:\", quantile_loss_linear_adjusted, \"\\n\",\n",
    "      \"Lasso loss: \", quantile_loss_lasso,  \"\\n\",\"Lasso adjusted loss:\", quantile_loss_lasso_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile Loss Unadjusted: 6.177996898726444 \n",
      " Quantile Loss Adjusted: 6.180261646999584\n"
     ]
    }
   ],
   "source": [
    "quantile_reg_model = sm.QuantReg(Y_train, X_train_const).fit(q=quantile)\n",
    "Y_pred_test = quantile_reg_model.predict(X_test_const)\n",
    "E_i = Y_test - Y_pred_test\n",
    "adjusted_quantile = quantile * (1 + 1 / len(E_i))\n",
    "Q_alpha_E = np.quantile(E_i, adjusted_quantile)\n",
    "X_validation_const = sm.add_constant(X_validation)\n",
    "Y_pred_validation = quantile_reg_model.predict(X_validation_const)\n",
    "Y_pred_validation_adjusted = Y_pred_validation + Q_alpha_E\n",
    "quantile_loss_unadjusted = quantile_loss(Y_validation, Y_pred_validation, quantile)\n",
    "quantile_loss_adjusted = quantile_loss(Y_validation, Y_pred_validation_adjusted, quantile)\n",
    "\n",
    "print(\"Quantile Loss Unadjusted:\", quantile_loss_unadjusted, \"\\n\",  \"Quantile Loss Adjusted:\", quantile_loss_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear loss unadjusted 6.43360836494513 loss_adjusted 6.172311214996229\n",
      "quantile loss unadjusted 6.198412529858875 loss_adjusted 6.180261646999584\n",
      "lasso loss unadjusted 6.4315991235322345 loss_adjusted 6.171379610664748\n",
      "ridge loss unadjusted 6.433607314207969 loss_adjusted 6.172309990028756\n",
      "random_forest loss unadjusted 6.503735257660947 loss_adjusted 6.283449996505407\n",
      "glm loss unadjusted 6.4336083649451306 loss_adjusted 6.172311214996229\n",
      "neural_network loss unadjusted 6.435181820395935 loss_adjusted 6.179402783093539\n"
     ]
    }
   ],
   "source": [
    "import ConformaQuantile as CQ\n",
    "\n",
    "\n",
    "models = ['linear', 'quantile', 'lasso', 'ridge', 'random_forest', 'glm', 'neural_network']\n",
    "for model in models:\n",
    "    CQ.perform_regression_analysis(X_observed, Y, train_ratio, test_ratio, \n",
    "                                validation_ratio, quantile, model_type = model)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
