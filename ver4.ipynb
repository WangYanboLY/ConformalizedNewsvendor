{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-linear Demand with misspecification\n",
    "\n",
    "$$\n",
    "D = f(X) + \\epsilon\n",
    "$$\n",
    "其中$f$为一个非线性函数$X = (X_1, X_2)$. 可以观测到的变量为$X_{\\text observed} = (X_1, X_3)$. 基于手中的数据希望得到一个$D|X_{\\text observed}$的条件分位数模型$g(X_{\\text observed})$. \n",
    "\n",
    "## 生成数据的方式f\n",
    "1. 考虑使用一个浅层神经网络构造非线性关系, 网络的参数随机生成或是先给定\n",
    "2. 考虑使用GLM来构造非线性关系，包括Poisson式，指数式等；\n",
    "3. 尝试polynomial等方法\n",
    "\n",
    "## 模型的选择g\n",
    "1. 线性模型 lasso, ridge and elastic net\n",
    "2. random\n",
    "3. Kernal-based regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## benchmark\n",
    "## misspecification\n",
    "1. non-linear 方法产生data - 用linear function去estimate\n",
    "2. 离散 - X_1, X_2, 均有正负，分为四个region, 在这四个region中Y|X的关系是不同的函数. \n",
    "3. 连续 - 类似于kernal based方法. 相近的X misspecification也相近？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ConformaQuantile as CQ\n",
    "\n",
    "quantile = 0.8\n",
    "n_samples = 10000\n",
    "n_X1 = 20\n",
    "n_X2 = 2\n",
    "n_X3 = 2\n",
    "interval_length = 100\n",
    "np.random.seed(0)\n",
    "\n",
    "X1 = abs(np.random.normal(6.4, 10, (n_samples, n_X1)))\n",
    "X2 = abs(np.random.normal(0.4, 1, (n_samples, n_X2)))\n",
    "X3 = abs(np.random.normal(0.9, 1, (n_samples, n_X3)))\n",
    "\n",
    "coefficients = abs(np.random.normal(10, 400, n_X1 + n_X2))\n",
    "X = np.hstack((X1, X2, X3))\n",
    "noise = np.random.normal(0, 1, n_samples)\n",
    "\n",
    "X_true = X[:, :(n_X1 + n_X2)]\n",
    "X_observed = np.hstack((X1, X3))\n",
    "Y = np.dot(X_true, coefficients)\n",
    "\n",
    "\n",
    "train_ratio = 0.6\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m Y0 \u001b[38;5;241m=\u001b[39m Y \u001b[38;5;241m+\u001b[39m noise\n\u001b[0;32m----> 2\u001b[0m loss_unadjusted, loss_adjusted \u001b[38;5;241m=\u001b[39m \u001b[43mCQ\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperform_regression_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_observed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                                                \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m                                                                  \u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mko\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/conformal/ConformaQuantile.py:96\u001b[0m, in \u001b[0;36mperform_regression_analysis\u001b[0;34m(X, Y, train_ratio, test_ratio, validation_ratio, quantile, model_type)\u001b[0m\n\u001b[1;32m     94\u001b[0m     Y_pred_validation \u001b[38;5;241m=\u001b[39m nn_model(X_validation)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mko\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m     Y_pred_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mpredict_kernel_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     97\u001b[0m     Y_pred_validation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([predict_kernel_quantile(X, Y, x, quantile) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_validation])\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantile_net\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/conformal/ConformaQuantile.py:96\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     94\u001b[0m     Y_pred_validation \u001b[38;5;241m=\u001b[39m nn_model(X_validation)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mko\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 96\u001b[0m     Y_pred_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mpredict_kernel_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_test])\n\u001b[1;32m     97\u001b[0m     Y_pred_validation \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([predict_kernel_quantile(X, Y, x, quantile) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X_validation])\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m model_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquantile_net\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/conformal/ConformaQuantile.py:50\u001b[0m, in \u001b[0;36mpredict_kernel_quantile\u001b[0;34m(X, Y, X_new, quantile, epsilon)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_kernel_quantile\u001b[39m(X, Y, X_new, quantile, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m):\n\u001b[1;32m     49\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X)\n\u001b[0;32m---> 50\u001b[0m     kernel_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mkernel_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     52\u001b[0m     low, high \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(Y), \u001b[38;5;28mmax\u001b[39m(Y)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m high \u001b[38;5;241m-\u001b[39m low \u001b[38;5;241m>\u001b[39m epsilon:\n",
      "File \u001b[0;32m~/conformal/ConformaQuantile.py:50\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_kernel_quantile\u001b[39m(X, Y, X_new, quantile, epsilon\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m):\n\u001b[1;32m     49\u001b[0m     n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(X)\n\u001b[0;32m---> 50\u001b[0m     kernel_weights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mkernel_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n)])\n\u001b[1;32m     52\u001b[0m     low, high \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(Y), \u001b[38;5;28mmax\u001b[39m(Y)\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m high \u001b[38;5;241m-\u001b[39m low \u001b[38;5;241m>\u001b[39m epsilon:\n",
      "File \u001b[0;32m~/conformal/ConformaQuantile.py:30\u001b[0m, in \u001b[0;36mkernel_function\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mkernel_function\u001b[39m(x1, x2):\n\u001b[1;32m     29\u001b[0m     sigma \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniforge3/envs/ML/lib/python3.11/site-packages/numpy/linalg/linalg.py:2527\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2525\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2526\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mdot(x)\n\u001b[0;32m-> 2527\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msqnorm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n\u001b[1;32m   2529\u001b[0m     ret \u001b[38;5;241m=\u001b[39m ret\u001b[38;5;241m.\u001b[39mreshape(ndim\u001b[38;5;241m*\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Y0 = Y + noise\n",
    "loss_unadjusted, loss_adjusted = CQ.perform_regression_analysis(X_observed, Y0, train_ratio, \n",
    "                                                                test_ratio, validation_ratio,\n",
    "                                                                  quantile, model_type='ko')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear loss unadjusted 6972.893055621992 loss_adjusted 125.59176725989416\n",
      "quantile loss unadjusted 6883.976768322941 loss_adjusted 126.35026095161547\n",
      "lasso loss unadjusted 6972.873227794408 loss_adjusted 125.58936046320991\n",
      "ridge loss unadjusted 6972.8803913867605 loss_adjusted 125.59206856755274\n",
      "random_forest loss unadjusted 6125.013594244923 loss_adjusted 1645.7233999817074\n",
      "glm loss unadjusted 6972.893055621939 loss_adjusted 125.59176725989492\n",
      "neural_network loss unadjusted 48039.76846665287 loss_adjusted 3569.170119478801\n",
      "\n",
      "拥有最小调整损失的模型：lasso\n",
      "\n",
      "拥有最大调整损失的模型：neural_network\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loss = {}\n",
    "models = ['linear', 'quantile', 'lasso', 'ridge', 'random_forest', 'glm', 'neural_network']\n",
    "\n",
    "Y0 = Y + noise\n",
    "for model in models:\n",
    "    loss_unadjusted, loss_adjusted = CQ.perform_regression_analysis(X_observed, Y0, train_ratio, test_ratio, validation_ratio, quantile, model_type=model)\n",
    "    # 将结果存储在字典中\n",
    "    loss[model] = {'loss_unadjusted': loss_unadjusted, 'loss_adjusted': loss_adjusted}\n",
    "\n",
    "min_loss_model = min(loss, key=lambda x: loss[x]['loss_adjusted'])\n",
    "max_loss_model = max(loss, key=lambda x: loss[x]['loss_adjusted'])\n",
    "\n",
    "print(f\"\\n拥有最小调整损失的模型：{min_loss_model}\")\n",
    "print(f\"\\n拥有最大调整损失的模型：{max_loss_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear loss unadjusted 0.3957079988701452 loss_adjusted 0.2816022719961405\n",
      "quantile loss unadjusted 0.28178398847513564 loss_adjusted 0.28188539424619086\n",
      "lasso loss unadjusted 0.39480938155817386 loss_adjusted 0.28117219634896695\n",
      "ridge loss unadjusted 0.3957079696762227 loss_adjusted 0.28160218570900497\n",
      "random_forest loss unadjusted 0.3982459967639985 loss_adjusted 0.2848042631490605\n",
      "glm loss unadjusted 0.3957079988701452 loss_adjusted 0.2816022719961405\n",
      "neural_network loss unadjusted 0.39462823210200826 loss_adjusted 0.2810275779209757\n",
      "\n",
      "拥有最小调整损失的模型：neural_network\n",
      "\n",
      "拥有最大调整损失的模型：random_forest\n"
     ]
    }
   ],
   "source": [
    "Y2 = -Y**(-1) + noise\n",
    "\n",
    "loss = {}\n",
    "models = ['linear', 'quantile', 'lasso', 'ridge', 'random_forest', 'glm', 'neural_network']\n",
    "for model in models:\n",
    "    loss_unadjusted, loss_adjusted = CQ.perform_regression_analysis(X_observed, Y2, train_ratio, test_ratio, validation_ratio, quantile, model_type=model)\n",
    "    # 将结果存储在字典中\n",
    "    loss[model] = {'loss_unadjusted': loss_unadjusted, 'loss_adjusted': loss_adjusted}\n",
    "\n",
    "min_loss_model = min(loss, key=lambda x: loss[x]['loss_adjusted'])\n",
    "max_loss_model = max(loss, key=lambda x: loss[x]['loss_adjusted'])\n",
    "\n",
    "print(f\"\\n拥有最小调整损失的模型：{min_loss_model}\")\n",
    "print(f\"\\n拥有最大调整损失的模型：{max_loss_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear loss unadjusted 0.3957080497667438 loss_adjusted 0.28160227079963746\n",
      "quantile loss unadjusted 0.2817841192360466 loss_adjusted 0.2818855075370898\n",
      "lasso loss unadjusted 0.39480943289008175 loss_adjusted 0.28117226368876835\n",
      "ridge loss unadjusted 0.39570802057299337 loss_adjusted 0.28160218451279706\n",
      "random_forest loss unadjusted 0.39817931893739117 loss_adjusted 0.2847167323341282\n",
      "glm loss unadjusted 0.39570804976674345 loss_adjusted 0.28160227079963746\n",
      "neural_network loss unadjusted 0.40951038463396383 loss_adjusted 0.28698669672736765\n",
      "\n",
      "拥有最小调整损失的模型：lasso\n",
      "\n",
      "拥有最大调整损失的模型：neural_network\n"
     ]
    }
   ],
   "source": [
    "Y3 = 1 / ( 1 + np.exp(-Y)) + noise\n",
    "loss = {}\n",
    "models = ['linear', 'quantile', 'lasso', 'ridge', 'random_forest', 'glm', 'neural_network']\n",
    "for model in models:\n",
    "    loss_unadjusted, loss_adjusted = CQ.perform_regression_analysis(X_observed, Y3, train_ratio, test_ratio, validation_ratio, quantile, model_type=model)\n",
    "    # 将结果存储在字典中\n",
    "    loss[model] = {'loss_unadjusted': loss_unadjusted, 'loss_adjusted': loss_adjusted}\n",
    "\n",
    "min_loss_model = min(loss, key=lambda x: loss[x]['loss_adjusted'])\n",
    "max_loss_model = max(loss, key=lambda x: loss[x]['loss_adjusted'])\n",
    "\n",
    "print(f\"\\n拥有最小调整损失的模型：{min_loss_model}\")\n",
    "print(f\"\\n拥有最大调整损失的模型：{max_loss_model}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
